<?xml version="1.0" encoding="utf-8"?>
<localize>
  <TextpageLeftNav template="2" createDate="2014-08-05T07:49:24" updateDate="2016-07-07T10:41:59" urlName="cognitive-services-emotion" writerName="content" creatorName="content">
    <bodyText><![CDATA[
      
            <tags ms.service="cognitive-services" ms.date="09/30/2015" wacn.date="11/27/2015"></tags>
            <style>
                .cognitive-banner{
                    margin: 30px 0;
                }
                .cognitive-figure{
                    padding-bottom: 30px;
                    margin-bottom: 30px;
                    border-bottom: 1px #ccc solid;
                    overflow: hidden;
                }
                .cognitive-figure .col-md-3{
                    padding-left: 0;
                    padding-right: 0;
                }
                .cognitive-figure .col-md-9{
                    padding-left: 2%;
                    padding-right: 0;
                }
                .pricing-page-section .cognitive-figure .col-md-9 h2, .container .pure-content .pricing-page-section .cognitive-icon-group .cognitive-text h2{
                    margin-top: 4px !important;
                }
                .cognitive-icon-group{
                    margin-top: 20px;
                    margin-bottom: 0;
                    list-style:none;
                    padding-left:0 !important;
                }
                .cognitive-icon-group li{
                    width:100%;
                    overflow:hidden;
                    margin-bottom: 30px !important;
                }
                .cognitive-icon-group li div{
                    float: left;
                }
                .cognitive-icon{
                    width: 10%;
                    min-width: 100px;
                    margin-right:-120px;
                }
                .cognitive-text{                   
                    margin-left:120px;
                }
                .cognitive-icon-group li:last-child{
                    margin-bottom: 0 !important;
                }
                @media only screen and (max-width: 769px){
                    .cognitive-figure{
                        padding-bottom: 20px;
                    }
                    .cognitive-figure .col-md-9{
                        padding-left: 0;
                    }
                    .pricing-page-section .cognitive-figure .col-md-9 h2{
                        margin-top: 26px !important;
                    }
                }
            </style>
            <!-- BEGIN: Cognitive-Services-TopBanner -->
            <div class="common-banner col-top-banner" data-config="{'backgroundColor':'#e3f4ff', 'backgroundImage':'//resource.cdn.azure.cn/marketing-resource/css/images/cognitive-emotion-api-slice-01.png','imageHeight':'auto'}">
                <div class="common-banner-image">
                    <div class="common-banner-title">
                        <img src="//resource.cdn.azure.cn/marketing-resource/css/images/home,features,cognitive-services,emotion.png" />
                        <h2>Emotion API <span style="color: #4d4d4d;font-family: '微软雅黑',regular;font-size: 20px;top: -6px;position: relative;display: inline;">(Preview)</span> <span>Emotion API</span></h2>
                        <h4>Analyzes the face to detect emotions and personalizes the application’s response.</h4>
                        <em><a href="/pricing/1rmb-trial/" id="emotion_1rmb-trial">Apply for 1RMB Trial<i class="icon icon-arrow-right-thin"></i></a></em> <a href="/pricing/pia/" id="emotion_pia">Buy Now<i class="icon icon-arrow-right-thin"></i></a>
                    </div>
                </div>
            </div>
            <!-- END: Cognitive-Services-TopBanner --> <!-- BEGIN: Cognitive-Services-Content -->
            <div class="pricing-page-section">
                <p><strong>We will retire the Preview version of the Emotion API on February 15, 2019, as the Emotion API functions have now been integrated with the Face API. Try <a href="/home/features/cognitive-services/face/">the Face API's emotion recognition function now</a>.</strong></p>
                <h2>Recognize mood from faces in pictures</h2> 
                <p>Emotion API uses a person’s facial expression in a picture as an input and returns an emotional confidence score for each facial expression in the picture. At the same time it takes a person’s face range to create a tag. If the user has already used the facial recognition API, it can also take the bounding box of a person’s face and make it an input item.</p>
				<p>It can detect if an emotion is anger, contempt, disgust, fear, happiness, neutral, sadness, and surprise. These emotions have characteristics that are recognized as being cross-cultural and universally expressed.</p>
                <img src="//resource.cdn.azure.cn/marketing-resource/css/images/cognitive-services-emotion-detect-emotions.png" class="cognitive-banner"/>
                          
            </div>
            <div class="pricing-page-section"> 
            

                <h1>Learn about the Cognitive Services API</h1>
                <ul class="cognitive-icon-group">
                    <li>
                        <div class="cognitive-icon"><img src="//resource.cdn.azure.cn/marketing-resource/css/images/home,features,cognitive-services,face.png"/></div>
                        <div class="cognitive-text">
                            <h2>Face API</h2>
                            <p>Detects relatively similar faces based on similar images grouped together, recognizing previously marked persons in the images.</p>
                            <p><a id="emotion_face" href="/home/features/cognitive-services/face/" class="single-link">More<i class="icon icon-arrow-right-thin"></i></a></p>
                        </div>
                    </li>                    
                    <li>
                        <div class="cognitive-icon"><img src="//resource.cdn.azure.cn/marketing-resource/css/images/home,features,cognitive-services,emotion.png"/></div>
                        <div class="cognitive-text">
                            <h2>Emotion API</h1>
                            <p>Analyzes the face to detect emotions and personalizes the application’s response.</p>
                            <p><a id="emotion_emotion" href="/home/features/cognitive-services/emotion/" class="single-link">More<i class="icon icon-arrow-right-thin"></i></a></p>
                        </div>
                    </li>
                    <li>
                        <div class="cognitive-icon"><img src="//resource.cdn.azure.cn/marketing-resource/css/images/home,features,cognitive-services,computer-vision.png"/></div>
                        <div class="cognitive-text">
                           <h2>Computer Vision API</h2>
                        <p>Extract enrichment data from images to categorize and handle visual data, inspect images with computer assistance, provide help for curation services.</p>
                        <p><a id="emotion_computer-vision" href="/home/features/cognitive-services/computer-vision/" class="single-link">More<i class="icon icon-arrow-right-thin"></i></a></p>
                        </div>
                    </li>
                </ul>
                    
            </div>
            <!--BEGIN: Support and service code chunk--> <?UMBRACO_MACRO chunkpath="production" chunkname="production-bottom-banner" macroAlias="blankCodeChunk" />  <!--END: Support and service code chunk--> <!-- END: Cognitive-Services-Content -->
                          
    
    ]]></bodyText>
    <pageTitle>Emotion API_Intelligent Apps – Azure Cloud Computing</pageTitle>
    <sitemapHide>0</sitemapHide>
    <linkid>Emotion API</linkid>
    <metaKeywords>Azure, Cognitive Services, Cognitive Services, Emotion</metaKeywords>
    <metaDescription><![CDATA[Azure Cognitive Services Emotion API uses facial expressions in a picture as an input and returns an emotional confidence score for each face in a picture. At the same time, it uses the Face API to take person’s face range to make a tag. If the user has already used the Face API, it can also take the frame of a person’s face and make it an input item. It can detect if an emotion is anger, contempt, disgust, fear, happiness, neutral, sadness, or surprise. These emotions have characteristics that are recognized as being cross-cultural and universally expressed.]]></metaDescription>
    <urlDisplayName>Cognitive Services – Emotion API</urlDisplayName>
  </TextpageLeftNav>
</localize>
